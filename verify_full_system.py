#!/usr/bin/env python3
"""
Verify that the full RAG system is working correctly with all 5,634 PDFs.
Tests: vector database, metadata, retrieval, and citation generation.
"""

import os

# CRITICAL: Set up cache BEFORE importing any HF libraries
HF_CACHE_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), ".hf_cache")
os.makedirs(HF_CACHE_DIR, exist_ok=True)
os.environ["HF_HOME"] = HF_CACHE_DIR
os.environ["HF_HUB_CACHE"] = os.path.join(HF_CACHE_DIR, "hub")
os.environ["TRANSFORMERS_CACHE"] = os.path.join(HF_CACHE_DIR, "transformers")
os.environ["SENTENCE_TRANSFORMERS_HOME"] = os.path.join(HF_CACHE_DIR, "sentence_transformers")
os.environ["HF_TOKEN_PATH"] = os.path.join(HF_CACHE_DIR, "token")
os.environ["HUGGINGFACE_HUB_CACHE"] = os.path.join(HF_CACHE_DIR, "hub")
os.environ["HF_HUB_DISABLE_TELEMETRY"] = "1"

import json
from pathlib import Path
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer

def main():
    print("="*70)
    print("FULL SYSTEM VERIFICATION")
    print("="*70)
    
    # 1. Check PDFs
    print("\n1. Checking PDF files...")
    pdf_dir = Path('downloaded_pdfs')
    pdf_files = list(pdf_dir.glob('*.pdf'))
    print(f"   ‚úì Found {len(pdf_files)} PDF files in {pdf_dir}")
    
    # 2. Check metadata
    print("\n2. Checking metadata...")
    with open('pdf_metadata.json', 'r') as f:
        metadata = json.load(f)
    
    with_authors = sum(1 for m in metadata.values() if m.get('authors') != 'Unknown Authors')
    with_year = sum(1 for m in metadata.values() if m.get('year') != 'n.d.')
    with_title = sum(1 for m in metadata.values() if m.get('title'))
    
    print(f"   ‚úì Metadata entries: {len(metadata)}")
    print(f"   ‚úì With real authors: {with_authors} ({with_authors/len(metadata)*100:.1f}%)")
    print(f"   ‚úì With year: {with_year} ({with_year/len(metadata)*100:.1f}%)")
    print(f"   ‚úì With title: {with_title} ({with_title/len(metadata)*100:.1f}%)")
    
    # 3. Check vector database
    print("\n3. Checking vector database...")
    client = QdrantClient(host="localhost", port=6333)
    
    collections = client.get_collections().collections
    print(f"   ‚úì Available collections: {[c.name for c in collections]}")
    
    collection_name = "academic_papers_100_specter2_v2"
    collection_info = client.get_collection(collection_name)
    
    print(f"\n   Collection: {collection_name}")
    print(f"   ‚úì Points (chunks): {collection_info.points_count}")
    print(f"   ‚úì Vector dimension: {collection_info.config.params.vectors.size}")
    print(f"   ‚úì Distance metric: {collection_info.config.params.vectors.distance}")
    print(f"   ‚úì Status: {collection_info.status}")
    
    # 4. Check embedding model
    print("\n4. Checking embedding model...")
    model = SentenceTransformer('allenai/specter2_base')
    dim = model.get_sentence_embedding_dimension()
    print(f"   ‚úì Model: allenai/specter2_base")
    print(f"   ‚úì Dimension: {dim}")
    print(f"   ‚úì Matches collection: {dim == collection_info.config.params.vectors.size}")
    
    # 5. Test retrieval
    print("\n5. Testing retrieval...")
    query = "machine learning for code analysis"
    query_vector = model.encode(query).tolist()
    
    results = client.query_points(
        collection_name=collection_name,
        query=query_vector,
        limit=10
    ).points
    
    print(f"   ‚úì Query: '{query}'")
    print(f"   ‚úì Retrieved {len(results)} results")
    
    if results:
        print(f"\n   Top 3 results:")
        for i, result in enumerate(results[:3], 1):
            filename = result.payload.get('filename', 'Unknown')
            score = result.score
            print(f"   [{i}] {filename} (score: {score:.3f})")
            
            # Check if metadata exists
            if filename in metadata:
                meta = metadata[filename]
                print(f"       Authors: {meta.get('authors', 'Unknown')}")
                print(f"       Title: {meta.get('title', 'Unknown')[:60]}...")
            else:
                print(f"       ‚ö†Ô∏è  No metadata found for {filename}")
    
    # 6. Summary
    print("\n" + "="*70)
    print("SYSTEM STATUS SUMMARY")
    print("="*70)
    
    pdf_match = len(pdf_files) == len(metadata)
    chunks_reasonable = collection_info.points_count > len(pdf_files)  # Should have multiple chunks per PDF
    
    print(f"\n‚úì PDFs in folder: {len(pdf_files)}")
    print(f"‚úì Metadata entries: {len(metadata)}")
    print(f"‚úì Vector chunks: {collection_info.points_count}")
    print(f"‚úì Author coverage: {with_authors/len(metadata)*100:.1f}%")
    print(f"‚úì Embedding model: SPECTER2 (768d)")
    print(f"‚úì Retrieval: Working")
    
    if pdf_match and chunks_reasonable and with_authors/len(metadata) > 0.95:
        print("\nüéâ SYSTEM FULLY OPERATIONAL!")
        print("   Ready to generate articles with proper citations.")
    else:
        print("\n‚ö†Ô∏è  ISSUES DETECTED:")
        if not pdf_match:
            print(f"   - PDF count ({len(pdf_files)}) doesn't match metadata ({len(metadata)})")
        if not chunks_reasonable:
            print(f"   - Vector chunks ({collection_info.points_count}) seems low for {len(pdf_files)} PDFs")
        if with_authors/len(metadata) <= 0.95:
            print(f"   - Author coverage ({with_authors/len(metadata)*100:.1f}%) is below 95%")

if __name__ == '__main__':
    main()
